args: Namespace(batch_size=64, test_batch_size=64, epochs=10, data_file_path='/Users/allen/ml/chinese_mnist/chinese_mnist.csv', img_folder_path='/Users/allen/ml/chinese_mnist/img')
   suite_id  ...                                           img_path
0         1  ...  /Users/allen/ml/chinese_mnist/img/input_1_1_10...
1         1  ...  /Users/allen/ml/chinese_mnist/img/input_1_10_1...
2         1  ...  /Users/allen/ml/chinese_mnist/img/input_1_2_10...
3         1  ...  /Users/allen/ml/chinese_mnist/img/input_1_3_10...
4         1  ...  /Users/allen/ml/chinese_mnist/img/input_1_4_10...

[5 rows x 6 columns]
/Users/allen/ml/ml_env/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 512, 60, 60]          13,312
         MaxPool2d-2          [-1, 512, 30, 30]               0
            Conv2d-3          [-1, 256, 26, 26]       3,277,056
         MaxPool2d-4          [-1, 256, 13, 13]               0
            Conv2d-5            [-1, 128, 9, 9]         819,328
         MaxPool2d-6            [-1, 128, 4, 4]               0
            Linear-7                  [-1, 512]       1,049,088
            Linear-8                  [-1, 128]          65,664
            Linear-9                   [-1, 15]           1,935
       LogSoftmax-10                   [-1, 15]               0
================================================================
Total params: 5,226,383
Trainable params: 5,226,383
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 19.33
Params size (MB): 19.94
Estimated Total Size (MB): 39.28
----------------------------------------------------------------
None
Epoch 1
-----------------------
loss: 2.356 [1216/12032]
loss: 1.802 [2496/12032]
loss: 1.431 [3776/12032]
loss: 1.175 [5056/12032]
loss: 0.902 [6336/12032]
loss: 0.719 [7616/12032]
loss: 0.600 [8896/12032]
loss: 0.648 [10176/12032]
loss: 0.535 [11456/12032]
Training Accuracy: 0.6459166666666667

Testing Accuracy: 0.8376666666666667

Epoch 2
-----------------------
loss: 0.486 [1216/12032]
loss: 0.430 [2496/12032]
loss: 0.394 [3776/12032]
loss: 0.306 [5056/12032]
loss: 0.262 [6336/12032]
loss: 0.292 [7616/12032]
loss: 0.275 [8896/12032]
loss: 0.295 [10176/12032]
loss: 0.307 [11456/12032]
Training Accuracy: 0.88775

Testing Accuracy: 0.9226666666666666

Epoch 3
-----------------------
loss: 0.233 [1216/12032]
loss: 0.225 [2496/12032]
loss: 0.190 [3776/12032]
loss: 0.206 [5056/12032]
loss: 0.136 [6336/12032]
loss: 0.206 [7616/12032]
loss: 0.245 [8896/12032]
loss: 0.230 [10176/12032]
loss: 0.170 [11456/12032]
Training Accuracy: 0.9335

Testing Accuracy: 0.9603333333333334

Epoch 4
-----------------------
loss: 0.114 [1216/12032]
loss: 0.123 [2496/12032]
loss: 0.132 [3776/12032]
loss: 0.102 [5056/12032]
loss: 0.100 [6336/12032]
loss: 0.111 [7616/12032]
loss: 0.128 [8896/12032]
loss: 0.135 [10176/12032]
loss: 0.154 [11456/12032]
Training Accuracy: 0.9598333333333333

Testing Accuracy: 0.9293333333333333

Epoch 5
-----------------------
loss: 0.138 [1216/12032]
loss: 0.187 [2496/12032]
loss: 0.130 [3776/12032]
loss: 0.098 [5056/12032]
loss: 0.113 [6336/12032]
loss: 0.086 [7616/12032]
loss: 0.063 [8896/12032]
loss: 0.085 [10176/12032]
loss: 0.045 [11456/12032]
Training Accuracy: 0.9655

Testing Accuracy: 0.963

Epoch 6
-----------------------
loss: 0.054 [1216/12032]
loss: 0.079 [2496/12032]
loss: 0.088 [3776/12032]
loss: 0.102 [5056/12032]
loss: 0.078 [6336/12032]
loss: 0.073 [7616/12032]
loss: 0.048 [8896/12032]
loss: 0.060 [10176/12032]
loss: 0.058 [11456/12032]
Training Accuracy: 0.9768333333333333

Testing Accuracy: 0.9743333333333334

Epoch 7
-----------------------
loss: 0.062 [1216/12032]
loss: 0.045 [2496/12032]
loss: 0.072 [3776/12032]
loss: 0.063 [5056/12032]
loss: 0.076 [6336/12032]
loss: 0.097 [7616/12032]
loss: 0.051 [8896/12032]
loss: 0.065 [10176/12032]
loss: 0.082 [11456/12032]
Training Accuracy: 0.9760833333333333

Testing Accuracy: 0.9766666666666667

Epoch 8
-----------------------
loss: 0.058 [1216/12032]
loss: 0.049 [2496/12032]
loss: 0.054 [3776/12032]
loss: 0.040 [5056/12032]
loss: 0.081 [6336/12032]
loss: 0.067 [7616/12032]
loss: 0.076 [8896/12032]
loss: 0.063 [10176/12032]
loss: 0.043 [11456/12032]
Training Accuracy: 0.9799166666666667

Testing Accuracy: 0.9713333333333334

Epoch 9
-----------------------
loss: 0.074 [1216/12032]
loss: 0.057 [2496/12032]
loss: 0.041 [3776/12032]
loss: 0.028 [5056/12032]
loss: 0.062 [6336/12032]
loss: 0.073 [7616/12032]
loss: 0.077 [8896/12032]
loss: 0.040 [10176/12032]
loss: 0.073 [11456/12032]
Training Accuracy: 0.9808333333333333

Testing Accuracy: 0.9656666666666667

Epoch 10
-----------------------
loss: 0.058 [1216/12032]
loss: 0.044 [2496/12032]
loss: 0.049 [3776/12032]
loss: 0.046 [5056/12032]
loss: 0.044 [6336/12032]
loss: 0.053 [7616/12032]
loss: 0.053 [8896/12032]
loss: 0.045 [10176/12032]
loss: 0.046 [11456/12032]
Training Accuracy: 0.9836666666666667

Testing Accuracy: 0.9846666666666667

